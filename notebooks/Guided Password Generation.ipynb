{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import trange\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "MODEL_PATH = \"javirandor/passgpt-10characters\"\n",
    "MAXCHARS = 10\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer from the model path\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_PATH, \n",
    "                                                max_len=MAXCHARS+2,\n",
    "                                                padding=\"max_length\", \n",
    "                                                truncation=True,\n",
    "                                                do_lower_case=False,\n",
    "                                                strip_accents=False,\n",
    "                                                mask_token=\"<mask>\",\n",
    "                                                unk_token=\"<unk>\",\n",
    "                                                pad_token=\"<pad>\",\n",
    "                                                truncation_side=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your PassGPT model\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_PATH).eval().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Password Generation\n",
    "One of the main advantages of PassGPT over PassGAN is the possibility of generating passwords under arbitrary constraints. In this template code, we have created five different groups of characters that we can sample from at each position:\n",
    "* `l`: lowercase letters\n",
    "* `u`: uppercase letters\n",
    "* `d`: digits\n",
    "* `p`: punctuation\n",
    "* `*`: any character in the vocabulary\n",
    "\n",
    "You can create any template by combining these. For example, `lllldd` will generate passwords starting with four lowercase letters and finishing with two digits.\n",
    "\n",
    "Feel free to create your own character groups below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each of the desired character groups into their corresponding ids (as given by the tokenizer)\n",
    "lowercase = list(string.ascii_lowercase)\n",
    "uppercase = list(string.ascii_uppercase)\n",
    "digits = list(string.digits)\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "lowercase_tokens = tokenizer(lowercase, add_special_tokens=False).input_ids\n",
    "uppercase_tokens = tokenizer(uppercase, add_special_tokens=False).input_ids\n",
    "digits_tokens = tokenizer(digits, add_special_tokens=False).input_ids\n",
    "punctuation_tokens = tokenizer(punctuation, add_special_tokens=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All possible tokens in our model\n",
    "all_tokens = [[i] for i in range(len(tokenizer))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_generation(template, num_generations=1):\n",
    "    generated = 0\n",
    "    generations = []\n",
    "    \n",
    "    while generated < num_generations:\n",
    "        generation = torch.tensor([tokenizer.bos_token_id]).unsqueeze(0)\n",
    "        current_length = 1\n",
    "\n",
    "        for char in template:\n",
    "            if char == \"l\":\n",
    "                bad_tokens = [i for i in all_tokens if i not in lowercase_tokens]\n",
    "            elif char == \"u\":\n",
    "                bad_tokens = [i for i in all_tokens if i not in uppercase_tokens]\n",
    "            elif char == \"d\":\n",
    "                bad_tokens = [i for i in all_tokens if i not in digits_tokens]\n",
    "            elif char == \"p\":\n",
    "                bad_tokens = [i for i in all_tokens if i not in punctuation_tokens]\n",
    "            else:\n",
    "                bad_tokens = [[tokenizer.eos_token_id]]\n",
    "\n",
    "            generation = model.generate(generation.to(DEVICE), do_sample=True, max_length=current_length+1, pad_token_id=tokenizer.pad_token_id, num_return_sequences=1,  bad_words_ids=bad_tokens)\n",
    "            current_length += 1\n",
    "        \n",
    "        if not 2 in generation.flatten():\n",
    "            generations.append(generation)\n",
    "            generated += 1\n",
    "    \n",
    "    return torch.cat(generations, 0)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = conditional_generation(\"uuuu**dd\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PARLA198', 'ANTHON64', 'JRWFX786', 'CELAN777', 'QWER1234']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
